### 1、保证消息消费的幂等性？

#### 1.1、重复消费的常见场景？

首先，比如RabbitMQ、RocketMQ、Kafka都有可能会出现重复消费的问题，这很正常。因为这个问题不是MQ来保证的，而是有应用程序开发时保证的。通过一个Kafka来举例说明，说说怎么重复消费？kafka有一个offset的概念，代表消息的序号，然后consumer消费了数据之后，每隔一段时间会把自己消费过的消息的offset提交一下，表示“我已经消费过了，下次我要是重启啥的，就让我继续从上次消费到的offset来继续消费吧”。但是凡事总会有意外，比如有时候重启系统直接用kill进程了，再重启。这会导致consumer有些消息处理了，但是没来得及提交offset了。重启之后，就会再次消费一次。

举个栗子。

有这样一个场景，数据1/2/3依次进入kafka，kafka会给这三条数据每条分配一个offset，代表这条数据的需要，我们就需要分配的offset依次是152/153/154。消费者进程被重启了。那么消费过的数据1/2的offset没有被提交，kafka也就不知道已经消费了offset=153这条数据了。那么重启之后，消费者会找kafka说，嘿，哥们儿，你给我接着把我上次消费的那个地方后面的数据继续给我传递过来。由于之前的offset没有提交成功，那么数据1/2会再次传递过来，如果此时消费者没有去重过滤的话，就会导致重复消费，出现数据问题。

<img src="/Users/tanglongan/Notes/消息队列/.images//image-20201013162223393.png" alt="image-20201013162223393" style="zoom:80%;" />

举个栗子。假设有一个系统，消费一条数据，就往数据库里插入一条数据，要是一个消息重复两次，插入了两条数据，这样就出现了问题。但是要是消费到第二条数据的时候，先判断一下是否已经消费过，若是就直接扔掉了，这样不就保留了一条数据，从而保证了数据的正确性。

`一条数据重复出现两次，数据库里就只有一条数据，这样就保证了数据消费的幂等性。`

`幂等性，通俗点说，就是一个数据或者一个请求，给你重复来多次，你的确保对应的数据是不会改变的，不能出错。`

怎么保证幂等性？

其实还是得结合业务来思考，这里有几个思路：

* 比如拿个数据写库，先根据主键查一下，如果这数据有了，就插入数据了，直接更新即可。
* 比如数据是写入redis，那没问题了，反正redis每次都是set，天然的幂等性
* 比如不是上面两种情况，那做的稍微复杂一点，需要让生产者发送每条数据的时候，里面加一个全局唯一的ID，类似订单ID的东西，然后消费的时候，先根据ID去比如redis里面查询一下，之前消费过吗？没有，就处理数据后写入redis，如果消费过了，就不用处理了，保证别重复处理相同消息即可。

![image-20201013164217809](/Users/tanglongan/Notes/消息队列/.images//image-20201013164217809.png)

当然，如何保证MQ的消费是幂等性的，需要结合具体业务来看。



### 2、保证消息的可靠性传输？

即数据丢失问题，可能出现在生产者、MQ、消费者中，从RabbitMQ和Kafka分别分析一下。

#### 2.1、RabbitMQ

##### 2.1.1、生产者弄丢了数据

生产者将数据发送到RabbitMQ的时候，可能数据就在半路丢失了，因为网络等问题。此时可以选择用RabbitMQ提供的事务功能，就是生产者发送数据之前开启RabbitMQ事务`channel.txSelect`，然后发送消息，如果消息没有成功被RabbitMQ接收到，那么生产者会收到异常报错，此时就可以回滚事务`channel.txRollback`，然后重试发送消息；如果收到消息，那么可以提交事务`channel.txCommit`。

```java
channel.txSelect();
try{
  //这里发送消息
}catch(Exception e){
  //回滚事务
  channel.txRollback();
  //这里再次发送消息
}
//提交事务
channel.txCommit();
```

但是问题是，`RabbitMQ事务机制开启之后，基本上吞吐量就降下来了，因为太耗性能。`

所以一般来说，如果要确保写RabbitMQ的消息别丢失，可以开启`confirm`模式，在生产者哪里设置开启`confirm`模式之后，每次写的消息都会分配一个唯一的ID，然后如果写入了RabbitMQ中，RabbitMQ会回传一个`ack`消息，告诉你这个消息OK了。如果RabbitMQ没能处理这个消息，会回调你的一个`nack`接口，告诉你这个消息接收失败，可以重试发送。而且可以结合这个机制在内存中维护每个消息ID的状态，如果超过一定时间还没接收到这个消息的回调，那么可以重发。

事务机制和`confirm`机制最大的不同在于，`事务机制是同步的`。你提交一个事务之后会阻塞在那里，但是`confirm机制是异步的`，你发送这个消息之后就可以发送下一个消息，然后那个消息RabbitMQ接收了之后会异步回调你的一个接口通知你这个消息收到了。

所以，`一般在生产者这边避免数据丢失，都是用confirm机制的。`

##### 2.1.2、RabbitMQ弄丢了数据

就是RabbitMQ自己弄丢了数据，这个必须开启`开启RabbitMQ的持久化`，就是消息写入之后会持久化到磁盘，哪怕是RabbitMQ自己挂了，恢复之后会自动读取之前存储的数据，一般不会丢失数据。除非极其罕见的是，RabbitMQ还没持久化，自己就挂了，可能导致丢失少量数据，但是这个概率极小。

设置持久化的两个步骤：

* 创建queue的时候，将其设置为持久化

  这样就可以保证RabbitMQ持久化queue的元数据，但是它是不会持久化queue里面的数据的。

* 发送消息的时候将消息的deliveryMode设置为2。

  就是将消息设置为持久化的，此时RabbitMQ会将消息持久化到磁盘上去。

必须同时设置这两个持久化才行，RabbitMQ哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里面的数据。注意哪怕是给RabbitMQ开启了持久化机制，也有一种可能是，就是这个消息写到了RabbitMQ中了，但是还没来得及持久化道磁盘上，结果不幸，RabbitMQ挂了，就会导致内存中一点点数据的丢失。所以持久化跟生产者那边的`confirm`机制配合起来，只有消息被持久化到磁盘后，才会通知生产者`ack`了，所以哪怕是在持久化到磁盘之前，RabbitMQ挂了，数据丢了，生产者收不到`ack`，也可以自己重发的。

##### 2.1.3、消费端丢失了数据

RabbitMQ如果丢失了数据，主要是因为你消费的时候，刚消费到，还没处理，结果进程挂了。比如重启了，那么就尴尬了，RabbitMQ认为都消费完了，这数据就丢了。这个时候就需要用RabbitMQ提供的`ack`机制，简单来说，就是你必须关闭RabbitMQ的自动`ack`，可以通过一个api来调用就行，然后每次你自己代码里面确保处理完的时候，再在程序里分配给别的consumer去处理，消息是不会丢失的。

![image-20201013202602869](/Users/tanglongan/Notes/消息队列/.images//image-20201013202602869.png)

### 3、保证消息的顺序性？

消息队列中的消息在某些业务场景下是有顺序的。

举个栗子，做一个MySQL的`binlog`同步的系统，日同步数据要达到上亿，就是说数据从一个MySQL库原封不动地同步到另外一个MySQL数据库中。常见的一点在于说比如大数据team，就需要同步一个MySQL库过来，然后对公司业务数据进行分析。当你MySQL里增删改一条数据，对应出来3条`binlog`日志，接着将这三条日志发送到MQ里面，再消费出来依次执行，起码得保证这三条数据的顺序。

#### 3.1、顺序错乱场景

* RabbitMQ：一个queue，多个consumer。比如生产者向RabbitMQ里发送了三条数据，顺序依次是data1/data2/data3，压入的是RabbitMQ的一个内存队列。有三个消费者分别从MQ中消费这三条数据中的一条，结果消费者2先执行完操作，把data2存入数据库，然后是data1/data3。这个明显就乱序了。

  <img src="/Users/tanglongan/Notes/消息队列/.images//image-20201014112745668.png" alt="image-20201014112745668" style="zoom:67%;" />

* Kafka：比如我们建了一个topic，有三个partition。生产者在写的时候，其实可以指定一个key，比如我们指定了某个订单id作为key，那么这个订单相关的数据，一定会被分发到同一个partition，而且这个partition中的数据一定是有顺序的。消费者从partition取出来数据的时候，也一定是有顺序的，到这里，顺序还是OK的。接着我们消费者里可能会搞多线程来并发处理消息。因为如果消费者是单线程消费处理，而处理比较耗时的话，比如处理一条消息耗时几十ms，那么1秒钟只能处理几十条消息，这吞吐量太低了而多线程并发跑的话，顺序可能就乱了。

  <img src="/Users/tanglongan/Notes/消息队列/.images//image-20201014112809997.png" alt="image-20201014112809997" style="zoom:67%;" />

#### 3.2、解决方案

* RabbitMQ：拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦点；或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，分发给底层不同的worker来处理。

  <img src="/Users/tanglongan/Notes/消息队列/.images//image-20201014113119034.png" alt="image-20201014113119034" style="zoom:67%;" />

* Kafka：

  * 一个topic，一个partition，一个consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。

  * 写N个内存queue，具有相同key的数据都发送到同一个内存queue；然后N个线程，每个线程分别消费一个内存queue即可，这样就能保证顺序性。

    <img src="/Users/tanglongan/Notes/消息队列/.images//image-20201014113343953.png" alt="image-20201014113343953" style="zoom:67%;" />

### 4、如何解决消息队列的延时以及过期失效问题？消息队列满了之后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？

面试官心理分析

可能在消费端出了问题，不消费了；或者消费端的处理速度极其慢。接着就坑爹了，可能消息队列集群的磁盘快要写满了，都没有消费，这个时候该怎么办？或者是这整个就积压了几个小时，你这个时候怎么办？或者你积压的时间太长了，到时比如RabbitMQ设置消息过期时间后就没有了，怎么办？

这个场景很常见，一般常见于消费端每次消费之后要写MySQL，结果MySQL挂了，消费端hang在那里了；或者消费端除了个什么岔子，导致消费端处理速度慢。

#### 4.1、大量消息在MQ中积压了几个小时还没处理

几千万条数据在MQ里积压了几个小时，这个时候要不然就是修复consumer的问题，让它恢复消费速度，然后傻傻地等待几个小时消费完毕。这个时候肯定不能在面试中讲。

一个消费者一秒是1000条，一秒3个消费者就是3000条，一分钟就是18万条。如果积压了几百万或者上千万的数据，即使消费者恢复了，也需要大概1小时的时间才能恢复过来。

一般这个时候，只能临时紧急扩容了，具体操作步骤和思路如下：

* 先修复consumer的问题，确保其恢复消费速度，然后将现有consumer都停掉。
* 新建一个topic，partition是原来的10倍，临时建立好原先10倍的queue数量。
* 然后写一个临时的分发数据的consumer程序，这个程度部署上去消费积压的数据，消费之后不做临时处理，直接均匀轮询写入临时建立好的10倍数量的queue。
* 接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数量。这种做法相当于临时将queue资源和consumer资源扩大了10倍，以正常的10倍速度来消费数据。
* 等快速消费外积压数据之后，得恢复原先部署的架构，重新用原先的consumer机器来消费数据。

#### 4.2、MQ中消息过期失效了

假设使用的是RabbitMQ，RabbitMQ是可以设置过期时间的，也就是TTL。如果消息在queue中积压超过了一定的时间就会被RabbitMQ给清理掉，这个数据就没有了。这是第二个坑。这就不是数据会大量积压在MQ里，而是大量的数据会直接搞丢了。

这个场景下，采取一个方案就是`批量重导`。就是大量积压的时候，直接丢弃数据了，然后等到过了高峰期以后，就用额外的补偿程序，一点点查询出来，然后重新灌入MQ里面去，把白天的数据找补回来。也只能这样了。假设1万个订单积压在MQ里面，没有处理，其中1000个订单都丢了，只能手动写程序把那1000个订单查询出来，手动发送到MQ中去进行消费处理。

#### 4.3、MQ快写满了

如果消息积压在MQ里面，很长时间都没有处理掉，此时导致MQ都快写满了，怎么办？这个还有别的办法么？没有！只能写临时程序接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，到系统业务空闲的时候在补偿数据处理。

### 5、如果让你写一个消息队列，如何进行架构设计？

这个问题一般是考察两点：

* 有没有对某一个消息队列做过较为深入的原理的了解，或者从整体上把我一个消息队列的架构原理。
* 考察设计能力，给一个常见的消息队列系统，能不能从全局把我一下整体架构设计，给出一些关键点。

回答系统设计的类似问题，起码要有相关技术的基本原理、核心组成部分、基本组成部分构成，然后参照一些开源技术把一个系统设计出来的思路说一下就好。

比如这个消息队列系统，从几个角度来考虑：

* 首先这个MQ得支持可伸缩性，就是需要的时候要快速扩容，就可以增加吞吐量和容量，那怎么搞？设计分布式系统形式，参照一下Kafka的设计理念，broker --> topic --> partition，每一个partition放一个机器，就存一部分数据。如果现在资源不够了，就给topic增加partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供吞吐量了。
* 其次需要考虑MQ的数据要不要落地磁盘？写入磁盘才能保证进程挂了之后数据丢失问题。落地磁盘要如何处理？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是Kafka的思路。
* 其次要不要考虑一下MQ的可用性？参考Kafka的高可用机制。多副本 --> leader & follwer --> broker挂了重新选举leader集合对外服务。
* 能不能支持数据零丢失？可以参考Kafka的数据零丢失方案。







