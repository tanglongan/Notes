### 如何保证缓存和数据库的双写一致性？

只要是涉及到缓存和数据库的双存储和双写操作，就一定会出现数据一致性的问题。

一般来说，如果允许缓存和数据库偶尔有不一致的情况，也就是说如果你的系统`不是严格要求`“缓存+数据库”必须保持一致的话，最好不要使用`读请求和写请求串行化，串到一个内存队列中去`的方案。串行化的方案可以保证一定不会出现不一致的情况，但是它会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。

**Cache Aside Pattern**

最经典的缓存+数据库读写的模式，就是Cache Aside Pattern。

* 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入数据库，同时返回响应。
* 更新的时候，`先更新数据库，然后删除缓存`

 **为什么是删除缓存，而不是更新缓存？**

原因很简单，很多时候，在复杂点的缓存场景中，缓存不单单是数据库中直接取出来的值。比如可能是更新了某个表的一个字段，然后对其对应的缓存，是需要查询另外两个表的数据进行运算，才能计算出缓存最新的值的。另外更新缓存的代价有时候是很高的，是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于比较复杂的缓存数据计算的场景，就不是这样的了。如果频繁修改一个缓存涉及的多个表，缓存也要频繁更新。但是问题在于，这个缓存到底会不会被频繁访问到？

举个栗子，一个缓存涉及的表的字段，在1分钟内修改了20次，或者100次，那么缓存更新20次，100次；但是这个缓存在1分钟只被读取了1次，有`大量的冷数据`。实际上，如果你只是删除缓存的话，那么在1分钟内这个缓存不过就重新计算一次而已，开销大幅度降低。`用到缓存才去运算缓存`。

其实删除缓存，而不是更新缓存，就是一个Lazy计算的思想，不要每次都重新做缓存的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。像mybatis、hibernate都有懒加载思想。

**最初级的缓存一致性问题及解决方案**

问题：先更新数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。

![image-20201014165440179](/Users/tanglongan/Notes/中间件/Redis/.images//image-20201014165440179.png)

解决思路：先删除缓存，再更新数据库。如果更新数据库失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会出现不一致。因为读的时候缓存没有，所以去读数据库中的旧数据，然后更新到缓存。

**比较复杂的数据不一致问题分析**

数据发生了变更，先删除了缓存，然后要修改数据库，此时还没修改。一个请求过来，去读缓存，发现缓存空了，去查询数据库，**查到了修改前的旧数据，放到了缓存中**。随后数据变更的程序完成了数据库的修改。完了，数据库和缓存中的数据不一致。

为什么上亿流量高并发的场景下，缓存会出现这个问题？

只有在对一个数据在并发的进行读写的时候，才可能出现这个问题。其实如果说你的并发量很低的话，特别是读并发很低，每天访问量就1万次，那么很少的情况下，会出现刚才描述的那种不一致的情况。但问题是，如果每天是上亿的流量，每秒并发读是几万，每秒只要有数据更新的请求，就可能会出现上述的数据库+缓存不一致的问题。

解决方案：

`数据库和缓存更新与读取操作进行异步串行化。`

异步串行化是什么意思？原因是双写不一致的情况下才会出现：

1. 先删除缓存，更新数据库。
2. 读缓存，发现缓存为空，从数据库获取数据，写入缓存。

这里的双写，一个是写数据库，一个是写缓存，并发导致问题。

异步串行化具体流程如下：

1. 更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个JVM内存的队列中。
2. 读取数据的时候，如果发现数据不在缓存中，那么将重新读取数据+更新缓存的操作，根据唯一路由标识之后，也发送同一个JVM内部的队列中。
3. 一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行

这样的话，`一个数据变更的操作，先执行，删除缓存，然后再去更新数据库，但是还没完成更新时，如果此时一个读请求过来，读到了空的缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成，待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取到最新的值，然后写入缓存中。如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么久直接返回；如果请求等待的时间超过了一定时长，那么这一次直接从数据库中读取当前的旧值。`

可优化的点：

* 一个队列中，其实多个更新缓存请求串在一起是没有意义的。因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么不用再放入更新请求操作进去了，直接等待前面的更新操作请求完成即可。比如，一个更新+写缓存操作后面跟了一个读操作，那么后续的读操作就可以过滤掉，不往队列中写，只需要等待缓存能获取到数据即可。
* 缓存为空，有可能不是在更新操作。
  * 有可能是：在执行更新操作，需要阻塞一会儿
  * 有可能是：数据库压根就没有该数据，那么可以判定下队列中是否有更新操作，没有则直接返回空的。

有一个疑问：万一是有该数据过期了呢？是正常的读缓存呢？

#### **高并发的场景下，该读解决方案要注意的问题**

* 读请求长时阻塞

  由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时的时间范围内返回。该解决方案，最大的风险点在于说，可能`数据更新很频繁`，导致队列中积压了大量更新操作在里面，然后读请求会发生大量的超时，最后导致大量的请求直接走数据库。

  另外一点，因为一个队列中，可能会积压针对多个数据项的更新操作，因此需要根据自己的业务情况进行测试，可能需要部署多个服务，每个服务分摊一些数据的更新操作。比如如果一个内存队列里居然会积压100个商品的库存修改操作，每个库存修改操作要耗时10ms去完成，那么最后一个商品的读请求，可能等待10 * 100 = 1000ms =1s后，才能得到数据。这个时候就会导致读请求的长时阻塞。

  一定要根据业务系统的运行情况，去进行一些压力测试，和模拟线上环境，去看看最繁忙的回收，内存队列可能会积压多少更新操作，可能会导致最后一个更新操作对应的读请求，会阻塞多少时间，如果要求读请求在200ms内完成，如果你计算过后，哪怕是最繁忙的时候，积压10个更新操作，最多等待200ms，那还可以的。如果一个内存队列可能积压的更新操作特别多，那么就需要增加机器，让每个机器上部署的服务实例处理更少的数据，那么每个内存队列中积压的更新操作就会更少。

  对于读高并发、读缓存的高并发架构一般写请求相对读来说，是非常非常少的。每秒的QPS能达到几百就不错了。一秒500的写操作，5份，每秒200ms，就100个写操作，单机器，20个内存队列，可能就积压5个写操作，每个写操作性能测试之后，一般在20ms左右就完成，那么针对每个队列中的数据的读请求，也就最多阻塞一会儿，200ms以内肯定能返回了。如果说写 QPS 扩大 10 倍，但是经过刚才的测算，就知道，单机支撑写 QPS 几百没问题，那么就扩容机器，扩容 10 倍的机器，10 台机器，每个机器 20 个队列，200 个队列。这么一大段的解说，主要是让你明白在高并发的超时需求下，需要严格的压测与计算

  大部分的情况下，应该是这样的，大量的读请求过来，都是直接走缓存取到数据的

  少量情况下，可能遇到读跟数据更新冲突的情况，如上所述，那么此时更新操作如果先入队列，之后可能会瞬间来了对这个数据大量的读请求，但是因为做了去重的优化，所以也就一个更新缓存的操作跟在它后面

  等数据更新完了，读请求触发的缓存更新操作也完成，然后临时等待的读请求全部可以读到缓存中的数据。

* 读请求并发量过高

  这里还必须做好压力测试，确保恰巧出现上述情况的时候，还有一个有风险的情况，就是突然大量读请求会在几十毫秒的延时hang在服务上，看服务能不能扛得住，需要多少机器才能抗住最大的极限情况的峰值。
  
  但是因为并不是所有的数据都在同一时间更新，更新也不会同一时间失效，所以每次也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量也不会特别大。
  
* 多服务实例部署的请求路由

  可能这个服务部署了多个实例，那么必须保证说，执行数据更新操作，以及执行缓存更新操作的请求，都通过Nginx服务器路由到相同的服务实例上。

  比如说，对于同一个商品的读写请求，全部路由到同一台机器上。可以自己去服务间的按照某个请求参数的hash路由，也可以用Nginx的hash路由功能等。

* 热点商品的路由问题，导致请求的倾斜

  万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能会造成某台机器的压力过大。也就是说，因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以其实要根据业务系统去看，如果更新频率不是太高的话，这个问题的影响并不是特别大，但是的确可能某些机器的负载会高一些。



































